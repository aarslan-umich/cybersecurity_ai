{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da4ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score ,  accuracy_score , precision_score , recall_score, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "from random import randrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b0a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_layer(nn.Module):\n",
    "    def __init__(self,in_channels = 1 , out_channels=128, dropout=0.4,padding='same',kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,padding=padding)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels,out_channels=out_channels,kernel_size=kernel_size,padding=padding)\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        self.norm =  nn.BatchNorm1d(out_channels)\n",
    "    def forward(self,x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x= F.elu(self.conv2(x))\n",
    "        x=self.dropout(x)\n",
    "        x= self.norm(x)\n",
    "        return x\n",
    "    \n",
    "class CNN_net(nn.Module):\n",
    "    def __init__(self,dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.layer1 = CNN_layer(in_channels=1,out_channels=128,dropout=dropout,kernel_size=7)\n",
    "        self.layer2 = CNN_layer(in_channels=128,out_channels=64,dropout=dropout,kernel_size=5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(31*64,120)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(120,60)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dense3 = nn.Linear(60,30)\n",
    "    def forward(self,x):\n",
    "        x= self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.flatten(x)\n",
    "        x=F.elu(self.dense1(x))\n",
    "        x=self.dropout1(x)\n",
    "        x=F.elu(self.dense2(x))\n",
    "        x=self.dropout2(x)\n",
    "        x=F.elu(self.dense3(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bdb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(dataset: pd.DataFrame):\n",
    "    if not isinstance(dataset, pd.DataFrame):\n",
    "        raise TypeError(\"You can olnly use Pandas Dataframe\")\n",
    "    sd_factor = [0.01,0.02,0.03,0.04,5]\n",
    "    header = []\n",
    "    sd=[]\n",
    "    for i in dataset.columns:\n",
    "        header.append(i)\n",
    "        if i ==\"subject\":\n",
    "            continue\n",
    "        sd.append(dataset[i].std())\n",
    "\n",
    "    generated_data = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        generated_data.append(dataset.loc[i].tolist())\n",
    "        for j in range(4):\n",
    "            row=[]\n",
    "            counter = 0\n",
    "            for k in dataset.columns:\n",
    "                if k ==\"subject\":\n",
    "                    row.append(dataset.loc[i,k])\n",
    "                    continue\n",
    "                row.append(dataset.loc[i,k]+(sd[counter]*sd_factor[j]))\n",
    "                counter=counter+1\n",
    "            generated_data.append(row)\n",
    "    generated_data = pd.DataFrame(generated_data)\n",
    "    generated_data.columns = header\n",
    "    return generated_data\n",
    "\n",
    "def generate_batch(x,batchsize):\n",
    "    batches =[]\n",
    "    for i in range(0,len(x),batchsize):\n",
    "        batch = x[i:i+batchsize]\n",
    "        tensor = torch.tensor(batch,dtype=torch.float)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        batches.append(tensor)\n",
    "    return batches\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e968e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DSL-StrongPasswordData.csv\")\n",
    "genuine  = data[data[\"subject\"]==\"s002\"]\n",
    "imposter = data[data[\"subject\"]!=\"s002\"] #users03 is imposter \n",
    "imposter = imposter.groupby(\"subject\").head(8)\n",
    "imposter = imposter.reset_index(drop=True)\n",
    "genuine = genuine.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9edb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 1, 31])\n"
     ]
    }
   ],
   "source": [
    "genuine = genuine.drop([\"sessionIndex\",\"rep\"],axis=1)\n",
    "imposter = imposter.drop([\"sessionIndex\",\"rep\"],axis=1)\n",
    "genuine = data_generation(genuine)\n",
    "imposter = data_generation(imposter)\n",
    "data2 = pd.concat([genuine,imposter],axis=0)\n",
    "X= data2.drop(\"subject\",axis=1)\n",
    "Y = data2[\"subject\"]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X=quantile_transform(X,n_quantiles=10, random_state=0, copy=True)\n",
    "Y = (Y != \"s002\").astype(int)\n",
    "\n",
    "X_train, X_test , Y_train , Y_test = train_test_split(X,Y,test_size=0.3,random_state=0,stratify=Y)\n",
    "X_train = generate_batch(X_train,8000)\n",
    "X_test = generate_batch(X_test,8000)\n",
    "X_train = X_train[0]\n",
    "X_test = X_test[0]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c17514c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111   9]\n",
      " [ 12 108]]\n"
     ]
    }
   ],
   "source": [
    "cnn  = CNN_net(dropout=0.4)\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    test_result=cnn(X_test)\n",
    "    train_result=cnn(X_train)\n",
    "test_result = test_result.detach().numpy()\n",
    "train_result = train_result.detach().numpy()\n",
    "catboost = CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "catboost.fit(train_result,Y_train)\n",
    "predicted = catboost.predict(test_result)\n",
    "\n",
    "f1 = f1_score(Y_test,predicted)\n",
    "accuracy = accuracy_score(Y_test,predicted)\n",
    "precision = precision_score(Y_test,predicted)\n",
    "recall = recall_score(Y_test,predicted)\n",
    "cm = confusion_matrix(Y_test,predicted)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0cc9a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9125 - Precision : 0.9231 - f1 : 0.9114 - Recall : 0.9000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy : {accuracy:.4f} - Precision : {precision:.4f} - f1 : {f1:.4f} - Recall : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d07bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
